**Cross Entropy (CE) loss:** a loss function calculated by taking the dot product of the ground truth vector and the log of the vector of output probabilities. <br>

**Gradient descent:** iterative algorithm used to find the minimum of the loss function. <br>

**Global minimum:** where the loss function takes the smallest value of its entire domain. <br>

**Learning rate:** scalar controlling the step size of the gradient descent algorithm. <br>

**Local minimum:** minimum in a local subset of the loss function domain. <br>

**Mean Absolute Error / L1 loss:** a loss function calculated by summing the absolute difference of the ground truths and the predictions. <br>

**Mean Square Error (MSE) / L2 loss:** a loss function calculated by summing the square difference of the ground truths and the predictions. <br>

**Optimizer:** other name for gradient descent algorithms. <br>
